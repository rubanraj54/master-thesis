%!TEX root = ../report.tex

\begin{document}
	\chapter{State of the art analysis} \label{stateof}
	
	\section{Semantic Data model}
	\citet{su2014connecting} highlights the interoperability issues in IoT sensor data and also says that these data should be useful for multiple applications rather than dependent on specific domain. To make the machines interpret the meaning of sensor data, author suggested to use Semantic Web technologies such as Resource Description Framework (RDF). Even though SenML is an evolving technique to model to sensor data, but it is lacking reasoning capabilities and interoperability with other devices. To overcome the issues in SenML generic model, author proposes a technique to represent IoT sensors as a Knowledge Based Systems by transforming SenML to Resource Description Framework. 
	
	As an advantage, the transformed data can be analyzed and helpful to take more meaningful actions. 
	SenML is specially designed for resource constrained devices, hence additional information to contextually understand the data has be not excluded intentionally. Each entry of SenML data should have the sensor parameter name and other attributes such as time, value, etc. Also it supports custom attribute called Resource Type (rt) to let the users add their own attributes and this allow users to include contextual information.
	
	With the help of transformation we could adopt RDF structure to model robot generated sensor data, But \citet{charpenay2018towards} points out that RDF data structure is not suitable for resource constrained devices like micro-controllers and also analyzed the issues in RDF such as verbosity and complexity in processing knowledge. To overcome this issues, author carried out an extensive analysis between RDF and JSON-LD structures. JSON-LD was published by W3C, and it serves as an alternative for RDF. Using JSON-LD one can represent the context for the data which is more important in robotics field such that other robots can understand the data based on context.
	
	Results shows that JSON-LD compaction coupled with EXI4-JSON or CBOR outperforms state-of-the-art (HDT) with \textbf{50 - 60 \% }compaction ratios.
	
	\section{Mediator architectures}
	\citet{fahl1993amos} proposed an active mediator architecture to gather in
	formation from different knowledge base and combine them to a single response. AMOS\footnote{\label{amos}Active Mediators Object System} architecture uses Object-Oriented approach to define declarative queries. This distributed architecture involves multiple mediator modules to work collaboratively to collect the required piece of information and produce final result. Primary components of AMOS architecture are,
	\begin{itemize}
		\item Integrator - Gather data from multiple data sources that have different data representations.
		\item Monitor - Monitor service always watch for any data changes and notifies the mediators. This is helpful in the case where system needs an active updates to change its current task.
		\item Domain models represents the models related to application which helps to access data easier from any database through a query language.
		\item Locators helps to locate mediators in the network.
	\end{itemize}
	
	
	Integrator module is built with two internal components called IAMOS\footnote{\label{amos}Integration Active Mediators Object System} and TAMOS\footnote{\label{amos}Translation Active Mediators Object System}. 
	First Integration AMOS parse the query and send individual requests to Translational AMOS modules which are responsible for heterogeneous data source.
	Then,all TAMOS modules return the individual results to IAMOS for integrating all the results. To query multi databases from IAMOS, IAMOS servers are mapped with TAMOS servers w+ith the help of Object-Oriented query language.
	
	
	\citet{ahmed1991pegasus} developed a heterogeneous multi-database system called Pegasus that supports multiple heterogeneous database systems with various data bases models, query languages and services. Pegasus predefines its domain data models based on sobject oriented approach and also supports programming capabilities. These objects are created and mapped with the types and functions with the help of HOSQL\footnote{\label{myfootnote}Heterogeneous Object Structured Query Language} statements. HOSQL is a declarative object oriented query language which is used by Pegasus to manipulate data from multiple data sources.
	
	
	
	Pegasus system supports two types of data sources, local and native data sources. Whenever a new data source joins Pegasus system, schema integrator module imports schema from data source and update its root schema with the new schema types. The final integrated schema shows the complete blueprint of the different data sources participates in the data integration. Pegasus system work-flow is comparatively similar to AMOS architecture, but they use different query language and data modeling strategies.
	
	\citet{chawathe1994tsimmis} developed project Tsimmiss extract information from any kind of data source and translates them to a meaningful common object. Unlike AMOS and Pegasus, Tsimmiss follows a straight forward approach to define the data model which is a self-describing object model. Each object must contain a label, type and value itself. Label can be used by the system to understand the meaning of the value and type shows the observed value type. Objects can be nested together to form a set of objects. 
	
	Tsimmiss tool offers a unique query language called OEM-QL and this language follows the SQL query language pattern to fetch the data from mediators. Mediators resolves the query and send separate requests to respective data sources to retrieve the information and merge them together to give a single response back to user. During data integration process, Tsimmiss removes possible duplicates to avoid redundancy in the response. Also, Tsimmiss bundles a default browser tool to query data using OEM-QL language.
	
	In the articles discussed above, mediators are targeted to extract information from different data sources that could be different databases or data from file-system. But Rufus system proposed by \citet{shoens1993rufus} focus only on semi structured data stored in file system for example documents, objects, programming files, mail, binary files, images etc. Rufus system classifier automatically classifies the type of file and apply a scanning mechanism on those files to extract the required information and transform them to the appropriate data model which is understandable by Rufus system. Rufus can classify 34 different classes of files. In terms of query language, Rufus can apply simple object predicates and finding text from the extracted information from the documents or files.
	
	\citet{papakonstantinou1996medmaker} proposes a Mediator Specification Language that helps the mediator to understand the schema and integrates the data from unstructured or semistructured source. MSL overcomes the major problems in existing mediator systems for example,
	\begin{itemize}
		\item Schema domain mismatch 
		\item Schematic discrepancy
		\item Schematic evaluation
		\item Structure irregularities
	\end{itemize}
	
	During translation of original information from different sources to a single object it should be important that, all data sources should have the required attribute and the name of the attribute should be same. Otherwise, mediator system will not be able to process the information to a single answer.  External predicates and Creation of the Virtual Objects in MSL solves the problems mentioned above.
	
	\citet{arens1996query} built a mediator which is flexible to map domain level query different data-sources and efficient to plan the query execution to reduce the overall execution time. Information source models provides relations between the super class and subclasses, and also the mapping between the domain models and information from heterogeneous sources. SIMS uses Loom as a representational language to make objects and relationship between them. SIMS supports parallel query access plan that makes the mediator to access information independent of data sources and the user will get the final answer as quick as possible.
	
	\section{Declarative data fetching frameworks}
	
	\citet{cederlund2016performance} performed an extensive comparison between REST, GraphQL and Falcor by declarative data fetching. They evaluated all three frameworks based on latency, data volume, and many requests with real-world test cases. Also, they analyzed the efficiency of filtering done by the frameworks.
	
	Their results reveal that Relay+GraphQL decreases the response time under parallel and sequential data flow. Furthermore, the response size is decreased when using the frameworks rather than REST API's. However, within the frameworks, Falcor response time and size is high compared to GraphQL. Ultimately, both the frameworks reduced the number of network calls to a single request.
	
	As a conclusion, \citet{cederlund2016performance} suggests to use custom REST endpoints since the frameworks increase the size of requests, but it still depends on the application requirement. In our application, Robots might work in the places where limited network access available, so we definitely use these frameworks as a base on our mediator to reduce the response size. Moreover, the observation data may have too many fields which are unnecessary for the other robots or tools to work on. Therefore only picking the necessary fields in the response profoundly reduce the response size as well as the response time.

	
	Many mediator systems developed in the past to support integrating heterogeneous information from different data sources. All of them built with different architectures, query language, and execution optimization. In our mediator approach we focus mainly on,
	\begin{itemize}
		\item How different type of robot generated data will be stored in multiple data sources?
		\item A unique context based data model to represent the components attached with each robot and data generated by them.
		\item Semantic query language to communicate with mediator. Unlike traditional query languages we would like to attempt new way of querying data, for example Graphql.
		\item GUI tool to visualize and analyze the robot generated data in a meaningful way.
	\end{itemize} 

\end{document}
