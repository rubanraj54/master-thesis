%!TEX root = ../report.tex

\begin{document}
    \chapter{Introduction}

Robots generate a large amount of data from different types of sensors attached to it and also from its hardware components. In our previous research work \cite{ravichandranworkbench}, we have conducted an extensive qualitative and quantitative analysis to find better databases and architectures that effectively store these data and consume it for further operations. Results from our previous work show that a single database is not suitable for every robotic scenario. For example, in terms of handling large BLOB data, MongoDB stored them faster but reading the data was slower compared to CouchDB \cite{ravichandranworkbench}. Also, to complete a given task robot depends on multiple sources of information from internal sensors, as well as external sources for example world model, kinematic model, etc.. 

Adoption of multiple databases for robotic applications requires a unique way of mediation to view multiple databases as a single federated database. The mediator approach helps to integrate data from different sources and produce an only result back to robots. Mediator abstracts the information of how data is being stored in various data sources from a robot and allows robotic applications stream data to mediator independent of databases used in the back-end.

To map the data generated by robots with multiple databases, the mediator system requires a proper data model predefined in the context of robotic applications. Modeling robot produced data helps to generalize the structure of data and defining relations between different entities (e.g., tasks,  sensors, robots, location ) in a robotic application scenario. If we have a well defined robotic data models, then the mediator will get the ability to mutate or query data from different data sources. Also, it is essential that any robotic use-cases should be able to extend these data models.


As mentioned in these papers \cite{ahmed1991pegasus,fahl1993amos,arens1996query,chawathe1994tsimmis,chawathe1994tsimmis,shoens1993rufus}, mediators are being used to integrate data from different data sources, and few architectures support single data model (e.g., SQL), and others recommend for different data models (e.g., SQL, NoSQL, document store, etc..). Also, they differ from query languages, ease of implementation, components used in their architecture. This project mainly focuses on defining semantic models for sensor data to make it more interoperable with other systems or even in multi-robot systems, and implementing a mediator system which acts as a middle-ware between robots and databases. 

    \section{Motivation}
    
		Streamlining the data produced from different sensors in robotic applications is a tedious task, and there are no specific standards to organize the data in terms of making relations between the entities and also giving context to the data. It will be even more complicated when we have a multi-robot platform and sharing data between them, and backing up the data into a database for fault diagnosis.
		
		Currently, in the ROPOD\footnote{ROPOD is an EU funded project to develop "Ultra-flat, ultra-flexible, and cost-effective robotic pods for handling legacy in logistics"} project, there is a single black box component has been designed with data loggers to run the robot test cases and store the sensor generated data in MongoDB. During the experimentation black box stores the data produced by the sensors as dumps into a single MongoDB instance locally. The three main challenges of data storage and retrieval are, 
		
		The first problem is, considering the sensor data stored as a collection of logs without data modeling makes the consumer\footnote{A consumer can be either humans or machines.} inability to execute queries against the data. 
		
		The second problem is missing contexts and the entity-relationship model. For example, if a consumer tries to query the data from dumps, then the consumer doesn't get additional information in the result such as which sensor produced this data from which robot/black-box at which location and time, and which person created the test case. What we mean by "missing context" is if humans read the data they will understand what's the meaning of each parameter, but if a different robot/black-box tries to consume the data produced by other robots then it will fail. Therefore the context about the data should be shared somewhere globally.
		
		Finally, sharing the data generated by multi-robots to solve a collaborative task and fetching data from multi-robots by a human controller to debug the test case.
		
		These significant issues inspired us to find a suitable Entity-Relationship data model and unique mediation system to query heterogeneous sensor data from multiple data sources regardless of the database type.


    \section{Structure}
	
		\begin{itemize}
			\item Section \ref{background} concisely describes the background knowledge of the topics which are relevant to this work.
			\item Section \ref{stateof} shows the related work which has been carried out earlier in the field of Federated databases and data modeling, and highlights the importance of declarative data fetching.
			\item Section \ref{sec:problem_statement} discusses problem formulation for this research work and section \ref{sec:concept_and_methodology} gives detailed explanation of our approach and methodology for the mediator system.
			\item Section \ref{sec:implementation} includes the complete implementation details of the mediator system.
			\item Section \ref{sec:evaluation} evaluates the developed mediator component based on requirements and existing black box data logger system in ROPOD project, and section \ref{sec:conclusion} shows the limitations and a road map for the future work. 
		\end{itemize}

\let\cleardoublepage\clearpage
\end{document}
